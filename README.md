## Leaderboards, Benchmarks & Evaluations
- [LMSYS Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
  - [LLM Judge](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge)
- [SWE-bench coding benchmark](https://www.swebench.com/)
- [Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
- [A holistic framework for evaluating foundation models](https://crfm.stanford.edu/helm/lite/latest/)
- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [EvalPlus Leaderboard](https://evalplus.github.io/leaderboard.html)
- [Collections](https://huggingface.co/collections/clefourrier/leaderboards-and-benchmarks-64f99d2e11e92ca5568a7cce)
- [Functional Benchmarks and the Reasoning Gap](https://github.com/ConsequentAI/fneval)
- [CodeMind is a generic framework for evaluating inductive code reasoning of LLMs. It is equipped with a static analysis component that enables in-depth analysis of the results.](https://github.com/Intelligent-CAT-Lab/CodeMind)
- [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://github.com/OpenCodeInterpreter)
- [OpenAI Evals](https://github.com/withmartian/martian-evals)
- [Yet Another Applied LLM Benchmark](https://github.com/carlini/yet-another-applied-llm-benchmark)
- [Evaluate-Iterate-Improve](https://github.com/uptrain-ai/uptrain)
- [Open-Source Evaluation for GenAI Application Pipelines](https://github.com/relari-ai/continuous-eval)  
- [OpenDevin](https://github.com/OpenDevin/OpenDevin)
- []()
- []()
- [Artificial Analysis](https://artificialanalysis.ai/)

## "Open" vs Closed 
- [Little guide to building Large Language Models in 2024](https://docs.google.com/presentation/d/1IkzESdOwdmwvPxIELYJi8--K3EZ98_cL6c5ZcLKSyVg/edit?usp=sharing)
- [Llama](https://llama.meta.com/)
- [OLMo](https://allenai.org/olmo)
- [Gemma](https://opensource.googleblog.com/2024/02/building-open-models-responsibly-gemini-era.html)
- [Robust recipes to align language models with human and AI preferences](https://github.com/huggingface/alignment-handbook)
- [A natural language interface for computers](https://github.com/KillianLucas/open-interpreter)
- []()

## Prompt
- [Anthropic Prompt library](https://docs.anthropic.com/claude/prompt-library)
- [Prompt Engineering with Llama 2](https://github.com/facebookresearch/llama-recipes/blob/main/examples/Prompt_Engineering_with_Llama_2.ipynb)

## GPTs

### Hugging Face Chat UI
- [Chat UI](https://github.com/huggingface/chat-ui)  
  - [Hugging Face's Chat Assistants](https://huggingface.co/chat/assistants)
  - [Open source implementation of the OpenAI 'data analysis mode' (aka ChatGPT + Python execution) based on Mistral-7B](https://github.com/xingyaoww/code-act) / [Hugging Face for Chat UI, ProjectJupyter for code executor](https://chat.xwang.dev)
- [Tokenizer Playground - How different models tokenize text](https://huggingface.co/spaces/Xenova/the-tokenizer-playground)

### Vercel Generative UI
- [AI RSC Demo](https://sdk.vercel.ai/demo)
  - [Prompt Playground](https://sdk.vercel.ai/prompt) Like Chatbot Arena https://chat.lmsys.org/
  - [AI SDK](https://sdk.vercel.ai/)
  - [v0](https://v0.dev/)
  
### Programming—not prompting—Language Models
- [Stanford DSPy: The framework for programming—not prompting—foundation models](https://github.com/stanfordnlp/dspy)
- [Stanford NLP Python Library for Understanding and Improving PyTorch Models via Interventions](https://github.com/stanfordnlp/pyvene)

### Scripting
- [LangChain OpenGPTs](https://github.com/langchain-ai/opengpts)
- [GPTScript](https://github.com/gptscript-ai/gptscript)
-

## Standards
- [Establishing industry wide AI best practices and standards for AI Engineers](https://github.com/AI-Engineer-Foundation)
- [The Data Provenance Initiative](https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection)

## Security
- [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://llm-attacks.org/)
- [How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs](https://chats-lab.github.io/persuasive_jailbreaker/)
- [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems)
- []()
- []()

## Articles & Talks
- [LLM App Stack aka Emerging Architectures for LLM Applications](https://github.com/a16z-infra/llm-app-stack)
- [A Guide to Large Language Model Abstractions](https://www.twosigma.com/articles/a-guide-to-large-language-model-abstractions/)
- [AI Fundamentals: Benchmarks 101](https://www.latent.space/p/benchmarks-101)
- [The Modern AI Stack: Design Principles for the Future of Enterprise AI Architectures](https://menlovc.com/perspective/the-modern-ai-stack-design-principles-for-the-future-of-enterprise-ai-architectures/)
- [AI Copilot Interfaces](https://byrnemluke.com/ideas/llm-interfaces)
- [Evaluating LLMs is a minefield](https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/)
- [Large Language Models and Theories of Meaning](https://drive.google.com/file/d/15oXHUBaUWwhFziB1G2Tg5kQ1PPJ3XqP7/view)
- [Predictive Human Preference(PHP)](https://huyenchip.com/2024/02/28/predictive-human-preference.html)

## AI Twitter
- [@karpathy](https://twitter.com/karpathy)
- [@simonw](https://twitter.com/simonw)
- []()
- [@antirez](https://twitter.com/antirez/status/1746857737584099781)
- [@ivanfioravanti](https://twitter.com/ivanfioravanti)

## Papers
- [Large Language Models: A Survey](https://arxiv.org/abs/2402.06196)
- [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/pdf/2304.12244.pdf)
- [RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture](https://arxiv.org/abs/2401.08406)
- [Multi-line AI-assisted Code Authoring](https://huggingface.co/papers/2402.04141)
- [Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models](https://arxiv.org/pdf/2402.14207.pdf)
- []()
- []()
- []()

## Learning
- [Minimal, clean code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization](https://github.com/karpathy/minbpe)
- [Large Language Model Course](https://github.com/mlabonne/llm-course)
- [Open-Source AI Cookbook](https://huggingface.co/learn/cookbook/index)
- [RAGStack](https://docs.datastax.com/en/ragstack/docs/index.html)
- [Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines](https://github.com/explodinggradients/ragas)
- [Easily use and train state of the art retrieval methods in any RAG pipeline. Designed for modularity and ease-of-use, backed by research](https://github.com/bclavie/RAGatouille)
- [Building the open-source feedback layer for LLMs](https://github.com/argilla-io)
- [Data Provenance Explorer](https://dataprovenance.org/)
- [SkyPilot: Run LLMs, AI, and Batch jobs on any cloud. Get maximum savings, highest GPU availability, and managed execution—all with a simple interface](https://github.com/skypilot-org)
